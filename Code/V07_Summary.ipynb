{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b70e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd  \n",
    "import random\n",
    "import math as mp\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import toml\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import model_from_yaml\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout\n",
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "\n",
    "from math import floor\n",
    "\n",
    "from ipynb.fs.full.V06_Utils  import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "53c2d0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Load Configuration\n",
    "######################################################################\n",
    "\n",
    "config_path = 'C:/Users/weikert1/Documents/Thesis/Project_V06_26072021/Code/V06_config.toml'\n",
    "cfg = toml.load(config_path)\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Load Directories \n",
    "######################################################################\n",
    "\n",
    "# Predicted Traces\n",
    "Path_dataset01_test = cfg['Path_dataset01']\n",
    "Path_dataset02_test = cfg['Path_dataset02']\n",
    "\n",
    "# LSTM quat \n",
    "Path_results_dataset01_LSTM_quat = cfg['Path_results_dataset01'] + \"LSTM_quat/\"\n",
    "Path_results_dataset02_LSTM_quat = cfg['Path_results_dataset02'] + \"LSTM_quat/\"\n",
    "\n",
    "# LSTM euler\n",
    "Path_results_dataset01_LSTM_euler = cfg['Path_results_dataset01'] + \"LSTM_euler/\"\n",
    "Path_results_dataset02_LSTM_euler = cfg['Path_results_dataset02'] + \"LSTM_euler/\"\n",
    "\n",
    "# GRU euler\n",
    "Path_results_dataset01_GRU_euler = cfg['Path_results_dataset01'] + \"GRU_euler/\"\n",
    "Path_results_dataset02_GRU_euler = cfg['Path_results_dataset02'] + \"GRU_euler/\"\n",
    "\n",
    "# Baseline euler\n",
    "Path_results_dataset01_Baseline_euler = cfg['Path_results_dataset01'] + \"Baseline_euler/\"\n",
    "Path_results_dataset02_Baseline_euler = cfg['Path_results_dataset02'] + \"Baseline_euler/\"\n",
    "\n",
    "# Baseline quat\n",
    "Path_results_dataset01_Baseline_quat = cfg['Path_results_dataset01'] + \"Baseline_quat/\"\n",
    "Path_results_dataset02_Baseline_quat = cfg['Path_results_dataset02'] + \"Baseline_quat/\"\n",
    "\n",
    "# Tensorflow configuration\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b019b4f6",
   "metadata": {},
   "source": [
    "# Result Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "716cacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# LSTM quat\n",
    "############################\n",
    "model_ID = cfg['1_2_model_ID'] \n",
    "Path_results_dataset01_LSTM_quat_model_id_evaluation =  Path_results_dataset01_LSTM_quat + \"/\" + model_ID + \"/Evaluation/\" \n",
    "Path_results_dataset02_LSTM_quat_model_id_evaluation =  Path_results_dataset02_LSTM_quat + \"/\" + model_ID + \"/Evaluation/\" \n",
    "\n",
    "############################\n",
    "# LSTM euler\n",
    "############################\n",
    "model_ID = cfg['2_1_model_ID'] \n",
    "Path_results_dataset01_LSTM_euler_model_id_evaluation =  Path_results_dataset01_LSTM_euler + \"/\" + model_ID + \"/Evaluation/\" \n",
    "Path_results_dataset02_LSTM_euler_model_id_evaluation =  Path_results_dataset02_LSTM_euler + \"/\" + model_ID + \"/Evaluation/\"\n",
    "\n",
    "############################\n",
    "# GRU euler\n",
    "############################\n",
    "model_ID = cfg['4_1_model_ID'] \n",
    "Path_results_dataset01_GRU_euler_model_id_evaluation =  Path_results_dataset01_GRU_euler + \"/\" + model_ID + \"/Evaluation/\" \n",
    "Path_results_dataset02_GRU_euler_model_id_evaluation =  Path_results_dataset02_GRU_euler + \"/\" + model_ID + \"/Evaluation/\" \n",
    "\n",
    "############################\n",
    "# Baseline euler\n",
    "############################\n",
    "\n",
    "Path_results_dataset01_Baseline_euler_model_id_evaluation =  Path_results_dataset01_Baseline_euler + \"/\" + \"/Evaluation/\" \n",
    "Path_results_dataset02_Baseline_euler_model_id_evaluation =  Path_results_dataset02_Baseline_euler + \"/\" + \"/Evaluation/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d13d02",
   "metadata": {},
   "source": [
    "# Evaluation Euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e5d928c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datasets = ['dataset_02']\n",
    "list_models = ['GRU_euler', 'LSTM_euler', 'Baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "64118030",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "def get_interim_results(path,dataset,model):\n",
    "    for csv in get_csv_files(path, \"*evaluation\"):\n",
    "        #print(csv)\n",
    "        basename = os.path.splitext(os.path.basename(csv))[0]\n",
    "        csv_df = pd.read_csv(csv, index_col=None, header=0)\n",
    "        add_basename = [basename] \n",
    "        add_dataset = [dataset]\n",
    "        add_model =[model]\n",
    "        csv_df['basename'] = add_basename\n",
    "        csv_df['dataset'] = add_dataset\n",
    "        csv_df['model'] = add_model\n",
    "        csv_df = csv_df[['dataset', 'model', 'basename', 'mae_ang_pitch', 'mae_ang_roll', 'mae_ang_yaw']]\n",
    "        frames.append(csv_df)\n",
    "    result = pd.concat(frames, axis=0, ignore_index=True)\n",
    "    return result \n",
    "\n",
    "def get_results():\n",
    "    for dataset in list_datasets:\n",
    "        for model in list_models:\n",
    "            if model == \"GRU_euler\":\n",
    "                if dataset == \"dataset_01\":\n",
    "                    path = Path_results_dataset01_GRU_euler_model_id_evaluation\n",
    "                    result = get_interim_results(path, dataset, model)\n",
    "                if dataset == \"dataset_02\":\n",
    "                    path = Path_results_dataset02_GRU_euler_model_id_evaluation\n",
    "                    result = get_interim_results(path, dataset, model)\n",
    "            if model == \"LSTM_euler\":\n",
    "                if dataset == \"dataset_01\":\n",
    "                    path = Path_results_dataset01_LSTM_euler_model_id_evaluation\n",
    "                    result = get_interim_results(path, dataset, model)\n",
    "                if dataset == \"dataset_02\":\n",
    "                    path = Path_results_dataset02_LSTM_euler_model_id_evaluation\n",
    "                    result = get_interim_results(path, dataset, model)\n",
    "            if model == \"Baseline\":\n",
    "                if dataset == \"dataset_01\":\n",
    "                    path = Path_results_dataset01_Baseline_euler_model_id_evaluation\n",
    "                    result = get_interim_results(path, dataset, model)\n",
    "                if dataset == \"dataset_02\":\n",
    "                    path = Path_results_dataset02_Baseline_euler_model_id_evaluation\n",
    "                    result = get_interim_results(path, dataset, model)\n",
    "    return result\n",
    "\n",
    "\n",
    "result = get_results()\n",
    "result.to_excel(os.path.join(cfg['Path_summary_results'], 'summary_results_euler_dataset02.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1ba4cb",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluation Quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a909dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>basename</th>\n",
       "      <th>mae_ang_pitch</th>\n",
       "      <th>mae_ang_roll</th>\n",
       "      <th>mae_ang_yaw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>GRU_euler</td>\n",
       "      <td>1_test_result_euler_lstm_evaluation</td>\n",
       "      <td>3.539182</td>\n",
       "      <td>5.589566</td>\n",
       "      <td>3.857692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>GRU_euler</td>\n",
       "      <td>2_test_result_euler_lstm_evaluation</td>\n",
       "      <td>3.904097</td>\n",
       "      <td>1.057998</td>\n",
       "      <td>3.168077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>GRU_euler</td>\n",
       "      <td>3_test_result_euler_lstm_evaluation</td>\n",
       "      <td>5.051243</td>\n",
       "      <td>3.576532</td>\n",
       "      <td>4.322400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>GRU_euler</td>\n",
       "      <td>5_test_result_euler_lstm_evaluation</td>\n",
       "      <td>3.599665</td>\n",
       "      <td>3.257677</td>\n",
       "      <td>2.876378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>LSTM_euler</td>\n",
       "      <td>1_test_result_euler_lstm_evaluation</td>\n",
       "      <td>6.374745</td>\n",
       "      <td>13.913673</td>\n",
       "      <td>5.721469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>LSTM_euler</td>\n",
       "      <td>2_test_result_euler_lstm_evaluation</td>\n",
       "      <td>7.786124</td>\n",
       "      <td>1.956451</td>\n",
       "      <td>4.645992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>LSTM_euler</td>\n",
       "      <td>3_test_result_euler_lstm_evaluation</td>\n",
       "      <td>10.052531</td>\n",
       "      <td>8.295125</td>\n",
       "      <td>6.420311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>LSTM_euler</td>\n",
       "      <td>5_test_result_euler_lstm_evaluation</td>\n",
       "      <td>6.130692</td>\n",
       "      <td>8.523539</td>\n",
       "      <td>4.453306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>1_test_result_rot_baseline_evaluation</td>\n",
       "      <td>1.547388</td>\n",
       "      <td>0.818611</td>\n",
       "      <td>2.635339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>2_test_result_rot_baseline_evaluation</td>\n",
       "      <td>1.698419</td>\n",
       "      <td>0.548735</td>\n",
       "      <td>2.245339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>3_test_result_rot_baseline_evaluation</td>\n",
       "      <td>1.985590</td>\n",
       "      <td>0.762527</td>\n",
       "      <td>2.816227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dataset_01</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>5_test_result_rot_baseline_evaluation</td>\n",
       "      <td>1.311440</td>\n",
       "      <td>0.642440</td>\n",
       "      <td>1.837527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset       model                               basename  \\\n",
       "0   dataset_01   GRU_euler    1_test_result_euler_lstm_evaluation   \n",
       "1   dataset_01   GRU_euler    2_test_result_euler_lstm_evaluation   \n",
       "2   dataset_01   GRU_euler    3_test_result_euler_lstm_evaluation   \n",
       "3   dataset_01   GRU_euler    5_test_result_euler_lstm_evaluation   \n",
       "4   dataset_01  LSTM_euler    1_test_result_euler_lstm_evaluation   \n",
       "5   dataset_01  LSTM_euler    2_test_result_euler_lstm_evaluation   \n",
       "6   dataset_01  LSTM_euler    3_test_result_euler_lstm_evaluation   \n",
       "7   dataset_01  LSTM_euler    5_test_result_euler_lstm_evaluation   \n",
       "8   dataset_01    Baseline  1_test_result_rot_baseline_evaluation   \n",
       "9   dataset_01    Baseline  2_test_result_rot_baseline_evaluation   \n",
       "10  dataset_01    Baseline  3_test_result_rot_baseline_evaluation   \n",
       "11  dataset_01    Baseline  5_test_result_rot_baseline_evaluation   \n",
       "\n",
       "    mae_ang_pitch  mae_ang_roll  mae_ang_yaw  \n",
       "0        3.539182      5.589566     3.857692  \n",
       "1        3.904097      1.057998     3.168077  \n",
       "2        5.051243      3.576532     4.322400  \n",
       "3        3.599665      3.257677     2.876378  \n",
       "4        6.374745     13.913673     5.721469  \n",
       "5        7.786124      1.956451     4.645992  \n",
       "6       10.052531      8.295125     6.420311  \n",
       "7        6.130692      8.523539     4.453306  \n",
       "8        1.547388      0.818611     2.635339  \n",
       "9        1.698419      0.548735     2.245339  \n",
       "10       1.985590      0.762527     2.816227  \n",
       "11       1.311440      0.642440     1.837527  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8c7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

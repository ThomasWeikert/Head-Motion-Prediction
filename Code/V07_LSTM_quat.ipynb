{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571dfe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd  \n",
    "import random\n",
    "import math as mp\n",
    "import pickle\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from pickle import load\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM, CuDNNGRU\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout, MaxPooling1D\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "import toml\n",
    "\n",
    "from math import floor\n",
    "\n",
    "from ipynb.fs.full.V06_Utils  import *\n",
    "from ipynb.fs.full.V06_Prepare_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45c215e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Init Configuration\n",
    "######################################################################\n",
    "\n",
    "config_path = 'C:/Users/weikert1/Documents/Thesis/Project_V06_26072021/Code/V06_config.toml'\n",
    "cfg = toml.load(config_path)\n",
    "\n",
    "# General \n",
    "n_in_seq = cfg['n_in_seq_quat']\n",
    "n_out_seq = cfg['n_out_seq_quat']\n",
    "n_steps = cfg['n_steps'] \n",
    "LAT_in_rows = cfg['LAT_in_rows'] #6*16,66ms= 64ms\n",
    "\n",
    "# model ID --> specify this for every new model\n",
    "model_id = cfg['1_2_model_ID']\n",
    "\n",
    "# Directories \n",
    "Path_dataset01_test = cfg['Path_dataset01']\n",
    "Path_results_dataset01_LSTM_quat_model_id = cfg['Path_results_dataset01'] + cfg['1_model_type'] + \"/\" + model_id  + \"/\" \n",
    "\n",
    "# Tensorflow configuration\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0576850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is: (71405, 15, 4)\n",
      "y shape is: (71405, 4)\n",
      "------\n",
      "X train shape is: (57124, 15, 4)\n",
      "X val shape is: (14281, 15, 4)\n",
      "y train shape is: (57124, 4)\n",
      "y val shape is: (14281, 4)\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Load Training Data\n",
    "######################################################################\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_training_data_quat(Path_dataset01_test)\n",
    "\n",
    "print(\"X train shape is: \" + str(X_train.shape))\n",
    "print(\"X val shape is: \" + str(X_val.shape))\n",
    "      \n",
    "print(\"y train shape is: \" + str(y_train.shape))\n",
    "print(\"y val shape is: \" + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4404df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7340308   0.02212691  0.6768867  -0.05033436]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d9f0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate(q):\n",
    "    mult = tf.constant(np.array([1,-1,-1,-1])[np.newaxis], dtype=np.float32)\n",
    "    return q*mult\n",
    "\n",
    "def inverse(q):\n",
    "    return conjugate(q) / tf.reduce_sum(q*q, axis=-1, keepdims=True)\n",
    "\n",
    "def log(q):\n",
    "    v = q[:, 1:]\n",
    "    a = q[:, :1]\n",
    "    q_norm = tf.norm(q, axis=-1, keepdims=True)\n",
    "    x = a / q_norm\n",
    "    eps = np.finfo(np.float32).eps * 8.0\n",
    "    x *= (1.0 - eps)\n",
    "    vec_part = tf.nn.l2_normalize(v, axis=-1) * tf.math.acos(x)\n",
    "    real_part = tf.math.log(q_norm)\n",
    "    return tf.concat([real_part, vec_part], axis=-1)\n",
    "\n",
    "def mult(quaternion1, quaternion2):\n",
    "    w1, x1, y1, z1 = tf.unstack(quaternion1, axis=-1)\n",
    "    w2, x2, y2, z2 = tf.unstack(quaternion2, axis=-1)\n",
    "    x = x1 * w2 + y1 * z2 - z1 * y2 + w1 * x2\n",
    "    y = -x1 * z2 + y1 * w2 + z1 * x2 + w1 * y2\n",
    "    z = x1 * y2 - y1 * x2 + z1 * w2 + w1 * z2\n",
    "    w = -x1 * x2 - y1 * y2 - z1 * z2 + w1 * w2\n",
    "    return tf.stack((w, x, y, z), axis=-1)\n",
    "    \n",
    "def geodesic_dist(q1, q2):\n",
    "    q1 = q1/tf.norm(q1)\n",
    "    q2 = q2/tf.norm(q2)\n",
    "    x = mult(inverse(q1), q2)\n",
    "    x = tf.norm(log(x), ord = 'euclidean', axis=-1)\n",
    "    return tf.reduce_mean(x)\n",
    "\n",
    "\n",
    "def angle_dist(q1, q2):\n",
    "    x = tf.reduce_sum(q1*q2, axis=-1)\n",
    "    eps = np.finfo(np.float32).eps * 8.0\n",
    "    x *= (1.0 - eps)\n",
    "    x = 2*tf.math.acos(x)\n",
    "    return tf.reduce_mean(x)\n",
    "\n",
    "\n",
    "def quat_antipodal_loss(y_true, y_pred):\n",
    "    dist1 = tf.reduce_mean(tf.abs(y_true-y_pred), axis=-1)\n",
    "    dist2 = tf.reduce_mean(tf.abs(y_true+y_pred), axis=-1)\n",
    "    loss = tf.where(dist1<dist2, dist1, dist2)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def euler_angles_loss(y_true, y_pred):\n",
    "    dist1 = tf.abs(y_true - y_pred)\n",
    "    dist2 = tf.abs(2*np.pi + y_true - y_pred)\n",
    "    dist3 = tf.abs(-2*np.pi + y_true - y_pred)\n",
    "    loss = tf.where(dist1<dist2, dist1, dist2)\n",
    "    loss = tf.where(loss<dist3, loss, dist3)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def mean_angle_btw_vectors(v1, v2):\n",
    "    dot_product = tf.reduce_sum(v1*v2, axis=-1)\n",
    "    cos_a = dot_product / (tf.norm(v1, axis=-1) * tf.norm(v2, axis=-1))\n",
    "    eps = 1e-8\n",
    "    cos_a = tf.clip_by_value(cos_a, -1 + eps, 1 - eps)\n",
    "    angle_dist = tf.math.acos(cos_a) / np.pi * 180.0\n",
    "    return tf.reduce_mean(angle_dist)\n",
    "\n",
    "def minmax_inverse_transform(y_true, y_pred):\n",
    "    path_scaler_objects = cfg['Path_scaler_object_quat']\n",
    "    w_min, x_min, y_min, z_min, w_max, x_max, y_max, z_max = load_scaler_objects(path_scaler_objects)\n",
    "    \n",
    "    w1, x1, y1, z1 = tf.unstack(y_true, axis=-1)\n",
    "    w2, x2, y2, z2 = tf.unstack(y_pred, axis=-1)\n",
    "    \n",
    "    w1, w2 = (w1 - K.constant(w_min)) / K.constant(w_max - w_min) , (w2 - K.constant(w_min)) / K.constant(w_max - w_min)\n",
    "    x1, x2 = (x1 - K.constant(x_min)) / K.constant(x_max - x_min) , (x2 - K.constant(x_min)) / K.constant(x_max - x_min)\n",
    "    y1, y2 = (y1 - K.constant(y_min)) / K.constant(y_max - y_min) , (y2 - K.constant(y_min)) / K.constant(y_max - y_min)\n",
    "    z1, z2 = (z1 - K.constant(z_min)) / K.constant(z_max - z_min) , (z2 - K.constant(z_min)) / K.constant(z_max - z_min)\n",
    "\n",
    "    y_true = tf.stack((w1, x1, y1, z1), axis=-1)\n",
    "    y_pred = tf.stack((w2, x2, y2, z2), axis=-1)\n",
    "    return y_true, y_pred\n",
    "\n",
    "def ang_mae(y_true,y_pred):\n",
    "    y_true, y_pred = minmax_inverse_transform(y_true, y_pred)\n",
    "    ang_dist_rad = geodesic_dist(y_true, y_pred) #returns a value between 0 and pi\n",
    "    #ang_dist_deg = rad2deg(ang_dist_rad)\n",
    "    shape = tf.cast(tf.size(ang_dist_rad),dtype=np.float32)\n",
    "    ang_mae =  K.sum(ang_dist_rad)/shape\n",
    "    return rad2deg(tf.reduce_mean(ang_mae))\n",
    "\n",
    "\n",
    "def rad2deg(rad):\n",
    "    pi_on_180 = 0.017453292519943295\n",
    "    return rad / pi_on_180\n",
    "\n",
    "\n",
    "def absolute_distance(q0, q1):\n",
    "    q0_minus_q1 = q0 - q1\n",
    "    q0_plus_q1  = q0 + q1\n",
    "    d_minus =  tf.norm(q0_minus_q1, axis=-1, keepdims=True) \n",
    "    d_plus  = tf.norm(q0_plus_q1, axis=-1, keepdims=True) \n",
    "    check = tf.math.less(d_minus, d_plus)\n",
    "    result = tf.where(check == True , d_minus, d_plus)\n",
    "    return tf.reduce_mean(result)\n",
    "\n",
    "\n",
    "def rotation_loss(q1, q2):\n",
    "    q1 = q1/tf.norm(q1)\n",
    "    q2 = q2/tf.norm(q2)\n",
    "    loss = q1 - q2\n",
    "    loss = tf.norm(loss)\n",
    "    return rad2deg(loss)\n",
    "\n",
    "\n",
    "def rotation_loss_2(y_true,y_pred):\n",
    "    rotation_loss = tf.sqrt(tf.nn.l2_loss(y_true-y_pred))\n",
    "    return tf.reduce_mean(rotation_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c9d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_LSTM(X_train, y_train, Neurons, Dropout_rate,Learning_rate):\n",
    "\n",
    "    # the dataset knows the number of features, e.g. 2\n",
    "    n_steps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\n",
    "\n",
    "    \n",
    "    ...\n",
    "    # define model\n",
    "    #model = Sequential()\n",
    "    \n",
    "    #model.add(CuDNNLSTM(100, return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    #model.add(Dropout(0.4))\n",
    "    \n",
    "    #model.add(CuDNNLSTM(100))\n",
    "    #model.add(Dropout(0.4))\n",
    "    \n",
    "    #model.add(CuDNNLSTM(100))\n",
    "    #model.add(Dropout(0.4))\n",
    "     \n",
    "    #model.add(Dense(100, activation='sigmoid'))\n",
    "    #model.add(Dense(n_features, activation='sigmoid'))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(CuDNNLSTM(Neurons, input_shape=(n_steps, n_features),return_sequences=True))\n",
    "    model.add(Dropout(Dropout_rate))\n",
    "    #model.add(CuDNNLSTM(128))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_features))\n",
    "    \n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=Learning_rate)\n",
    "    #model.compile(opt, loss=tf.keras.losses.Huber() , metrics = geodesic_dist) #run_eagerly=True\n",
    "    model.compile(opt, loss=angle_dist) #run_eagerly=True\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1224f2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "print(\"-----\")\n",
    "#model = My_LSTM(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db9370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53c1519d",
   "metadata": {},
   "source": [
    "# Train the mdel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68988724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model checkpoint\n",
    "#mc = ModelCheckpoint(Path_results_dataset01_LSTM_quat_model_id + \"/Model/\" + model_id + '_CUDNNLSTM_quat_best_model.h5', monitor ='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5906a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quat_hist = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=Batch_size, epochs=Epochs, verbose=1, callbacks=[mc] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "743f93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "# serialize model to YAML\n",
    "    model_yaml = model.to_yaml()\n",
    "    with open(path +  \"_CUDNN_arch.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_yaml)\n",
    "\n",
    "\n",
    "    #model.save_weights(save_path + \"V05_CUDNNLSTM_rotation_20072021.h5\")\n",
    "    return print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e1b6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAT_in_rows = [1,2,3,4,5,6,7,8,9,10]\n",
    "Neurons = [64,128,256,512]\n",
    "Dropout_rate = [10,20,30,40,50,60,70,80,90]\n",
    "Learning_rate = [10,100,1000,10000,100000,1000000,10000000]\n",
    "Batch_size = [1028,512,256,128,64]\n",
    "Epochs = [100,200,300,400,500]\n",
    "#Loss = [quat_antipodal_loss,absolute_distance,geodesic_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e40cb820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9d87017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is: (71405, 15, 4)\n",
      "y shape is: (71405, 4)\n",
      "------\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 15, 64)            17920     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               96100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 114,424\n",
      "Trainable params: 114,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Blas xGEMM launch failed : a.shape=[1,1028,960], b.shape=[1,960,100], m=1028, n=100, k=960\n\t [[node sequential/dense/MatMul (defined at <ipython-input-14-08bdaa99e1c2>:11) ]] [Op:__inference_train_function_1359]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-08bdaa99e1c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         \u001b[0mmc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath_results_dataset01_LSTM_quat_model_id\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/Model/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mindividual_name\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[1;34m'_CUDNN_best_model.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                         \u001b[0mcsv_logger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath_results_dataset01_LSTM_quat_model_id\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/Model/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mindividual_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBatch_size_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEpochs_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                         \u001b[0mloss_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  Blas xGEMM launch failed : a.shape=[1,1028,960], b.shape=[1,960,100], m=1028, n=100, k=960\n\t [[node sequential/dense/MatMul (defined at <ipython-input-14-08bdaa99e1c2>:11) ]] [Op:__inference_train_function_1359]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "for Neurons_i in Neurons:\n",
    "    for Dropout_rate_i in Dropout_rate:\n",
    "        for Learning_rate_i in Learning_rate:\n",
    "            for Batch_size_i in Batch_size:\n",
    "                for Epochs_i in Epochs:\n",
    "                        X_train, X_val, y_train, y_val = prepare_training_data_quat(Path_dataset01_test)\n",
    "                        model = My_LSTM(X_train, y_train, Neurons_i, 1/Dropout_rate_i , 5/Learning_rate_i)\n",
    "                        individual_name = \"Neurons_\" + str(Neurons_i) + \"_\" + \"_DR_\" + str(Dropout_rate_i) + \"__\" + \"LR_\" + str(Learning_rate_i) + \"__\" + \"Batch_\" + str(Batch_size_i) + \"__\" + \"Epochs_\" + str(Epochs_i) \n",
    "                        mc = ModelCheckpoint(Path_results_dataset01_LSTM_quat_model_id + \"/Model/\" + individual_name +  '_CUDNN_best_model.h5', monitor ='val_loss', mode='min', save_best_only=True, verbose=0)\n",
    "                        csv_logger = CSVLogger(Path_results_dataset01_LSTM_quat_model_id + \"/Model/\" + individual_name + '.csv', append=True, separator=';')\n",
    "                        history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=Batch_size_i, epochs=Epochs_i, verbose=1, callbacks=[mc,csv_logger] )\n",
    "                        loss_history = history.history[\"loss\"]\n",
    "                        plt.plot(history.history['loss'])\n",
    "                        plt.plot(history.history['val_loss'])\n",
    "                        plt.title('model loss')\n",
    "                        plt.ylabel('loss')\n",
    "                        plt.xlabel('epoch')\n",
    "                        plt.legend(['train', 'test'], loc='upper left')\n",
    "                        plt.show()\n",
    "                        save_model(model,Path_results_dataset01_LSTM_quat_model_id + \"/Model/\" + individual_name )\n",
    "                        tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d45637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0fe7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4c9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf00ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

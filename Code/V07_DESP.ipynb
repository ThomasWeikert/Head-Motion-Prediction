{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd  \n",
    "import random\n",
    "import math as mp\n",
    "import pickle\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from pickle import load\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pyquaternion import Quaternion\n",
    "%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, Input, Lambda\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM, CuDNNGRU\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout, MaxPooling1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "import toml\n",
    "from math import floor\n",
    "\n",
    "from ipynb.fs.full.V07_Utils  import *\n",
    "from ipynb.fs.full.V07_Prepare_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Init Configuration\n",
    "######################################################################\n",
    "\n",
    "config_path = 'C:/Users/Thomas Weikert/Documents/Thesis/Project_V07_24092021/Code/V07_config.toml'\n",
    "cfg = toml.load(config_path)\n",
    "\n",
    "# General \n",
    "n_in_seq = cfg['n_in_seq_quat']\n",
    "n_out_seq = cfg['n_out_seq_quat']\n",
    "n_steps = cfg['n_steps'] \n",
    "LAT_in_rows = cfg['LAT_in_rows'] #6*16,66ms= 64ms\n",
    "\n",
    "# model ID --> specify this for every new model\n",
    "model_id = cfg['8_1_model_ID']\n",
    "model_type = cfg['8_model_type']\n",
    "\n",
    "# Directories \n",
    "Path_dataset01_test = cfg['Path_dataset01']\n",
    "Path_results_dataset01_DESP_quat_model_id = cfg['Path_results_dataset01'] + model_type + \"/\" + model_id  + \"/\" \n",
    "\n",
    "# Tensorflow configuration\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pos_metrics(true_pos, preds_pos):\n",
    "        # Compute Eucliden and angular distances\n",
    "        euc_dists = np.linalg.norm(true_pos - preds_pos, axis=1)\n",
    "        #print(euc_dists)\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae_euc = sum(euc_dists) / euc_dists.shape[0]\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse_euc = np.sqrt((euc_dists ** 2).mean())\n",
    "        return euc_dists, mae_euc, rmse_euc\n",
    "\n",
    "\n",
    "def compute_quat_metrics(true_rot, preds_rot,true_rot_quat, preds_rot_quat):\n",
    "        # Compute Eucliden and angular distances\n",
    "        ang_dists = np.array([Quaternion.distance(q1, q2) for q1, q2 in zip(true_rot_quat, preds_rot_quat)]) #(w, x, y, z)\n",
    "        euc_dists = np.linalg.norm(true_rot - preds_rot, axis=1)\n",
    "        # Mean Absolute Error (MAE)\n",
    "        #mae_ang = np.rad2deg(np.sum(ang_dists) / ang_dists.shape[0])\n",
    "        #mae_euc = np.rad2deg(np.sum(euc_dists) / euc_dists.shape[0])\n",
    "        \n",
    "        mae_ang = (np.sum(ang_dists) / ang_dists.shape[0])\n",
    "        mae_euc = (np.sum(euc_dists) / euc_dists.shape[0])\n",
    "        \n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse_ang = np.rad2deg(np.sqrt((ang_dists ** 2).mean()))\n",
    "        rmse_euc = np.rad2deg(np.sqrt((euc_dists ** 2).mean()))\n",
    "        return euc_dists, ang_dists, mae_ang, mae_euc, rmse_ang, rmse_euc\n",
    "\n",
    "def eval_quat(true_rot, preds_rot):\n",
    "        true_rot_quat = np.array([Quaternion(q) for q in true_rot]) #(w, x, y, z)\n",
    "        preds_rot_quat = np.array([Quaternion(q) for q in preds_rot]) #(w, x, y, z)    \n",
    "        \n",
    "        return compute_quat_metrics(true_rot, preds_rot,true_rot_quat, preds_rot_quat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look Ahead Time: 5\n",
      "C:/Users/Thomas Weikert/Documents/Thesis/Project_V07_24092021/Data/01_Dataset\\1_full_continious.csv\n",
      "Single Predictions are saved\n",
      "Number of dists: 34993\n",
      "MAE_euc position is : 0.0032673587898332562\n",
      "RMSE_euc rotation is : 0.005060128711987785\n",
      "----\n",
      "C:/Users/Thomas Weikert/Documents/Thesis/Project_V07_24092021/Data/01_Dataset\\2_full_continious.csv\n",
      "Single Predictions are saved\n",
      "Number of dists: 14993\n",
      "MAE_euc position is : 0.003383198188416322\n",
      "RMSE_euc rotation is : 0.00510993949822753\n",
      "----\n",
      "C:/Users/Thomas Weikert/Documents/Thesis/Project_V07_24092021/Data/01_Dataset\\3_full_continious.csv\n",
      "Single Predictions are saved\n",
      "Number of dists: 44993\n",
      "MAE_euc position is : 0.003138752567041892\n",
      "RMSE_euc rotation is : 0.004705439366115982\n",
      "----\n",
      "C:/Users/Thomas Weikert/Documents/Thesis/Project_V07_24092021/Data/01_Dataset\\4_full_continious.csv\n",
      "Single Predictions are saved\n",
      "Number of dists: 69993\n",
      "MAE_euc position is : 0.00330702297781126\n",
      "RMSE_euc rotation is : 0.005612973031276649\n",
      "----\n",
      "C:/Users/Thomas Weikert/Documents/Thesis/Project_V07_24092021/Data/01_Dataset\\5_full_continious.csv\n",
      "Single Predictions are saved\n",
      "Number of dists: 19993\n",
      "MAE_euc position is : 0.0022544989175734987\n",
      "RMSE_euc rotation is : 0.0035316780668127783\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print(\"Look Ahead Time: \" + str(LAT_in_rows))\n",
    "\n",
    "for csv in get_csv_files(Path_dataset01_test, \"full*cont\"):\n",
    "    basename = os.path.splitext(os.path.basename(csv))[0]\n",
    "    print(csv)\n",
    "    \n",
    "    dataframe = load_df(csv)\n",
    "    \n",
    "    # define sequences\n",
    "    seq1 = dataframe[['x']].to_numpy()\n",
    "    seq2 = dataframe[['y']].to_numpy()\n",
    "    seq3 = dataframe[['z']].to_numpy()\n",
    "    \n",
    "    seq1 = seq1.reshape((len(seq1), 1))\n",
    "    seq2 = seq2.reshape((len(seq2), 1))\n",
    "    seq3 = seq3.reshape((len(seq3), 1))\n",
    "    \n",
    "    # horizontally stack columns\n",
    "    dataset = hstack((seq1, seq2, seq3)) \n",
    "\n",
    "    dataset_p1 = dataset[:-1]\n",
    "    dataset_p2 = dataset[1:]\n",
    "    delta = np.array([(p1-p2) for p1, p2 in zip(dataset_p1,dataset_p2)])\n",
    "    \n",
    "    \n",
    "    sqt_prev = np.array([0,0,0])\n",
    "    sqt2_prev = np.array([0,0,0])\n",
    "    \n",
    "    t = LAT_in_rows\n",
    "    alphas = [0.496]\n",
    "    \n",
    "    for alpha in alphas: \n",
    "        prediction_result = []\n",
    "        \n",
    "        # Perform SE\n",
    "        for pos in delta[:-LAT_in_rows]:\n",
    "\n",
    "            f = alpha * t / (1 - alpha)\n",
    "\n",
    "            sqt_x = (alpha * pos[0]) + ((1 - alpha) * sqt_prev[0])\n",
    "            sqt_y = (alpha * pos[1]) + ((1 - alpha) * sqt_prev[1])\n",
    "            sqt_z = (alpha * pos[2]) + ((1 - alpha) * sqt_prev[2])\n",
    "\n",
    "            sqt2_x = (alpha * sqt_x) + ((1 - alpha) * sqt2_prev[0])\n",
    "            sqt2_y = (alpha * sqt_y) + ((1 - alpha) * sqt2_prev[1])\n",
    "            sqt2_z = (alpha * sqt_z) + ((1 - alpha) * sqt2_prev[2])\n",
    "\n",
    "            pred_x = (2 + f) * sqt_x - (1 + f) * sqt2_x\n",
    "            pred_y = (2 + f) * sqt_y - (1 + f) * sqt2_y\n",
    "            pred_z = (2 + f) * sqt_z - (1 + f) * sqt2_z\n",
    "            result = np.array([pred_x, pred_y, pred_z])\n",
    "\n",
    "            sqt_prev = np.array([sqt_x,sqt_y,sqt_z])\n",
    "            sqt2_prev = np.array([sqt2_x,sqt2_y,sqt2_z])\n",
    "\n",
    "            prediction_result.append(result)\n",
    "\n",
    "        dataset_pred = np.array(prediction_result)\n",
    "        dataset_true = delta[LAT_in_rows:]\n",
    "        \n",
    "        # Create dataframe for prediction & gt per timestamp and concate results \n",
    "        df_preds_pos = pd.DataFrame(np.row_stack(dataset_pred), columns= cfg['pos_coords_pred'])\n",
    "        df_true_pos = pd.DataFrame(np.row_stack(dataset_true), columns= cfg['pos_coords_true'])\n",
    "        df_rot_result = pd.concat([df_preds_pos, df_true_pos], axis=1)\n",
    "        df_rot_result.to_csv(os.path.join(Path_results_dataset01_DESP_quat_model_id + \"/Traces\", basename + '_result_pos_DESP.csv'), index=False)\n",
    "        print(\"Single Predictions are saved\")\n",
    "\n",
    "        euc_dists, mae_euc, rmse_euc = compute_pos_metrics(dataset_pred, dataset_true)\n",
    "        print('Number of dists: ' + str(euc_dists.shape[0]))\n",
    "        print('MAE_euc position is : ' + str(mae_euc))\n",
    "        print('RMSE_euc rotation is : ' + str(rmse_euc))\n",
    "        print(\"----\")\n",
    "        \n",
    "         ############ Save metrices\n",
    "        result_one_experiment = list([[mae_euc,rmse_euc]])\n",
    "        df_results = pd.DataFrame(result_one_experiment, columns=['mae_euc','rmse_euc'])\n",
    "        df_results.to_csv(os.path.join(Path_results_dataset01_DESP_quat_model_id + \"/Evaluation\", basename + '_pos_evaluation.csv'), index=False)\n",
    "\n",
    "        ############ Save angular distances\n",
    "        dist_one_experiment = np.array(euc_dists).flatten()\n",
    "        dists_one_experiment = pd.DataFrame(dist_one_experiment, columns=['euc_dists'])\n",
    "        dists_one_experiment.to_csv(os.path.join(Path_results_dataset01_DESP_quat_model_id + \"/Evaluation\", basename + '_pos_dists.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look Ahead Time: 5\n",
      "C:/Users/Thomas Weikert/Documents/Thesis/Project_V07_24092021/Data/01_Dataset\\5_full_continious.csv\n",
      "0.61\n",
      "Single Predictions are saved\n",
      "Number of dists: 19992\n",
      "MAE_euc position is : 0.00496613254378738\n",
      "RMSE_euc rotation is : 0.4284428668842418\n",
      "----\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Quaternion Delta\n",
    "######################\n",
    "\n",
    "print(\"Look Ahead Time: \" + str(LAT_in_rows))\n",
    "\n",
    "for csv in get_csv_files(Path_dataset01_test, \"5*full*cont\"):\n",
    "    print(csv)\n",
    "    basename = os.path.splitext(os.path.basename(csv))[0]\n",
    "    \n",
    "    dataframe = load_df(csv)\n",
    "    \n",
    "    # define sequences\n",
    "    seq1 = dataframe[['qw']].to_numpy()\n",
    "    seq2 = dataframe[['qx']].to_numpy()\n",
    "    seq3 = dataframe[['qy']].to_numpy()\n",
    "    seq4 = dataframe[['qz']].to_numpy()\n",
    "    \n",
    "    seq1 = seq1.reshape((len(seq1), 1))\n",
    "    seq2 = seq2.reshape((len(seq2), 1))\n",
    "    seq3 = seq3.reshape((len(seq3), 1))\n",
    "    seq4 = seq4.reshape((len(seq4), 1))\n",
    "    \n",
    "    # horizontally stack columns\n",
    "    dataset = hstack((seq1, seq2, seq3, seq4)) \n",
    "    \n",
    "    \n",
    "    dataset_q1 = ([Quaternion(q) for q in dataset[:-1]])\n",
    "    dataset_q2 = ([Quaternion(q) for q in dataset[1:]])\n",
    "    delta = np.array([(q1/q2).elements for q1, q2 in zip(dataset_q1,dataset_q2)])\n",
    "    \n",
    "    t = LAT_in_rows\n",
    "    alphas = [0.61]\n",
    "    \n",
    "    for alpha in alphas: \n",
    "        \n",
    "        print(alpha)\n",
    "        \n",
    "        prediction_result = []\n",
    "        continious_dataset = []\n",
    "        state_changes = []\n",
    "        \n",
    "        sqt_prev = np.array([0,0,0,0])\n",
    "        sqt2_prev = np.array([0,0,0,0])\n",
    "        \n",
    "        ##################################################################################################\n",
    "        # DESP\n",
    "        ##################################################################################################\n",
    "        \n",
    "        for rot in delta[:-LAT_in_rows]:\n",
    "        #for rot in dataset[:10]:\n",
    "            \n",
    "            \n",
    "            #print(\"rot: \" + str(rot))\n",
    "            #print(\"-Ticke----------\")\n",
    "\n",
    "            f = alpha * t / (1 - alpha)\n",
    "            \n",
    "\n",
    "            sqt_w = (alpha * rot[0]) + ((f - alpha) * sqt_prev[0])\n",
    "            sqt_x = (alpha * rot[1]) + ((f - alpha) * sqt_prev[1])\n",
    "            sqt_y = (alpha * rot[2]) + ((f - alpha) * sqt_prev[2])\n",
    "            sqt_z = (alpha * rot[3]) + ((f - alpha) * sqt_prev[3])\n",
    "\n",
    "            sqt2_w = (alpha * sqt_w) + ((f - alpha) * sqt2_prev[0])\n",
    "            sqt2_x = (alpha * sqt_x) + ((f - alpha) * sqt2_prev[1])\n",
    "            sqt2_y = (alpha * sqt_y) + ((f - alpha) * sqt2_prev[2])\n",
    "            sqt2_z = (alpha * sqt_z) + ((f - alpha) * sqt2_prev[3])\n",
    "\n",
    "            q_pred_w = (2 + f) * sqt_w - (1 + f) * sqt2_w;\n",
    "            q_pred_x = (2 + f) * sqt_x - (1 + f) * sqt2_x;\n",
    "            q_pred_y = (2 + f) * sqt_y - (1 + f) * sqt2_y;\n",
    "            q_pred_z = (2 + f) * sqt_z - (1 + f) * sqt2_z;\n",
    "            \n",
    "            #Quaternion_result_norm = np.linalg.norm(np.array([q_pred_w, q_pred_x, q_pred_y, q_pred_z]))\n",
    "            #Quaternion_result = np.array([q_pred_w, q_pred_x, q_pred_y, q_pred_z])/Quaternion_result_norm\n",
    "            \n",
    "            q_res_unit = Quaternion([q_pred_w, q_pred_x, q_pred_y, q_pred_z]).unit\n",
    "            q_res_unit = np.array([q_res_unit[0],q_res_unit[1],q_res_unit[2],q_res_unit[3]])\n",
    "            \n",
    "            #print(q_res_unit)\n",
    "            \n",
    "            sqt_prev = Quaternion([sqt_w,sqt_x,sqt_y,sqt_z]).unit\n",
    "            sqt_prev = np.array([sqt_prev[0],sqt_prev[1],sqt_prev[2],sqt_prev[3]])\n",
    "            #print(sqt_prev)            \n",
    "            \n",
    "            sqt2_prev_normal = np.array([sqt2_w,sqt2_x,sqt2_y,sqt2_z])\n",
    "            #print(\"normal: \" + str(sqt2_prev_normal))\n",
    "            sqt2_prev = Quaternion([sqt2_w,sqt2_x,sqt2_y,sqt2_z]).unit\n",
    "            #print(\"Quat: \" + str(sqt2_prev))\n",
    "            sqt2_prev = np.array([sqt2_prev[0],sqt2_prev[1],sqt2_prev[2],sqt2_prev[3]])\n",
    "            #print(\"After :\" + str(sqt2_prev))\n",
    "            #print(\"-----\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            #sqt_prev_norm = np.linalg.norm(np.array([sqt_w,sqt_x,sqt_y,sqt_z]))\n",
    "            #sqt_prev = np.array([sqt_w,sqt_x,sqt_y,sqt_z])/sqt_prev_norm\n",
    "            \n",
    "            #sqt2_prev_norm = np.linalg.norm(np.array([sqt2_w,sqt2_x,sqt2_y,sqt2_z]))\n",
    "            #sqt2_prev = np.array([sqt2_w,sqt2_x,sqt2_y,sqt2_z])/sqt2_prev_norm\n",
    "            \n",
    "            prediction_result.append(q_res_unit)\n",
    "        \n",
    "        ##################################################################################################\n",
    "        # Checking continiousity of predicted data\n",
    "        ##################################################################################################\n",
    "        \n",
    "        dataset_pred = np.array(prediction_result)\n",
    "        dataset_pred = np.array([Quaternion(q) for q in dataset_pred]) \n",
    "        dataset_true = delta[LAT_in_rows:]\n",
    "        \n",
    "        \n",
    "        \n",
    "        def representation_1(q):\n",
    "            quaternion = []\n",
    "            quaternion.append([q[0],q[1],q[2],q[3]])\n",
    "            return np.array(quaternion).reshape(4,)\n",
    "    \n",
    "        def representation_2(q):\n",
    "            quaternion = []\n",
    "            quaternion.append([-q[0],-q[1],-q[2],-q[3]])\n",
    "            return np.array(quaternion).reshape(4,)\n",
    "\n",
    "        for q1,q2 in zip(dataset_pred[:-1],dataset_pred[1:]):\n",
    "            if Quaternion.distance(q1,q2) <= Quaternion.distance(q1,-q2):\n",
    "                state_changes.append(0)\n",
    "            else:\n",
    "                state_changes.append(1)\n",
    "\n",
    "        cum_sum = np.cumsum(np.array(state_changes))\n",
    "\n",
    "        for idx,state in enumerate(cum_sum):\n",
    "            if state%2 == 0:\n",
    "                continious_dataset.append(representation_2(dataset_pred[idx+1]))\n",
    "            else:\n",
    "                continious_dataset.append(representation_1(dataset_pred[idx+1]))\n",
    "\n",
    "        \n",
    "        #print(\"Bevor\")\n",
    "        #print(dataset_pred)\n",
    "        #print(\"Groundtruth\")\n",
    "        #print(dataset_true)\n",
    "        #print(\"after\")\n",
    "        #print(np.array(continious_dataset))\n",
    "        \n",
    "        \n",
    "        euc_dists, ang_dists, mae_ang, mae_euc, rmse_ang, rmse_euc = eval_quat(continious_dataset, dataset_true[:-1])\n",
    "        \n",
    "        \n",
    "        # Create dataframe for prediction & gt per timestamp and concate results \n",
    "        df_preds_rot = pd.DataFrame(np.row_stack(continious_dataset), columns= cfg['quat_coords_pred'])\n",
    "        df_true_rot = pd.DataFrame(np.row_stack(dataset_true[:-1]), columns= cfg['quat_coords_true'])\n",
    "        df_rot_result = pd.concat([df_preds_rot, df_true_rot], axis=1)\n",
    "        df_rot_result.to_csv(os.path.join(Path_results_dataset01_DESP_quat_model_id + \"/Traces\", basename + '_delta_result_quat_DESP.csv'), index=False)\n",
    "        print(\"Single Predictions are saved\")\n",
    "        \n",
    "        print('Number of dists: ' + str(euc_dists.shape[0]))\n",
    "        print('MAE_euc position is : ' + str(mae_euc))\n",
    "        print('RMSE_euc rotation is : ' + str(rmse_euc))\n",
    "        \n",
    "         ############ Save metrices\n",
    "        result_one_experiment = list([[mae_ang,mae_euc,rmse_ang,rmse_euc]])\n",
    "        df_results = pd.DataFrame(result_one_experiment, columns=['mae_ang','mae_euc','rmse_ang','rmse_euc'])\n",
    "        df_results.to_csv(os.path.join(Path_results_dataset01_DESP_quat_model_id + \"/Evaluation\", basename + '_delta_quat_evaluation.csv'), index=False)\n",
    "\n",
    "        ############ Save angular distances\n",
    "        dist_one_experiment = list(ang_dists)\n",
    "        dists_one_experiment = pd.DataFrame(dist_one_experiment, columns=['ang_dists'])\n",
    "        dists_one_experiment.to_csv(os.path.join(Path_results_dataset01_DESP_quat_model_id + \"/Evaluation\", basename + '_delta_quat_dists.csv'), index=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"----\")\n",
    "        print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Quaternion Absolut\n",
    "######################\n",
    "\n",
    "\n",
    "\n",
    "print(\"Look Ahead Time: \" + str(LAT_in_rows))\n",
    "\n",
    "for csv in get_csv_files(Path_dataset01_test, \"full*cont\"):\n",
    "    print(csv)\n",
    "    basename = os.path.splitext(os.path.basename(csv))[0]\n",
    "    \n",
    "    dataframe = load_df(csv)\n",
    "    \n",
    "    # define sequences\n",
    "    seq1 = dataframe[['qw']].to_numpy()\n",
    "    seq2 = dataframe[['qx']].to_numpy()\n",
    "    seq3 = dataframe[['qy']].to_numpy()\n",
    "    seq4 = dataframe[['qz']].to_numpy()\n",
    "    \n",
    "    seq1 = seq1.reshape((len(seq1), 1))\n",
    "    seq2 = seq2.reshape((len(seq2), 1))\n",
    "    seq3 = seq3.reshape((len(seq3), 1))\n",
    "    seq4 = seq4.reshape((len(seq4), 1))\n",
    "    \n",
    "    # horizontally stack columns\n",
    "    dataset = hstack((seq1, seq2, seq3, seq4)) \n",
    "    \n",
    "    \n",
    "    #dataset_q1 = ([Quaternion(q) for q in dataset[:-1]])\n",
    "    #dataset_q2 = ([Quaternion(q) for q in dataset[1:]])\n",
    "    #delta = np.array([(q1/q2).elements for q1, q2 in zip(dataset_q1,dataset_q2)])\n",
    "    \n",
    "    t = LAT_in_rows\n",
    "    alphas = [0.61]\n",
    "    \n",
    "    for alpha in alphas: \n",
    "        \n",
    "        print(alpha)\n",
    "        \n",
    "        prediction_result = []\n",
    "        continious_dataset = []\n",
    "        state_changes = []\n",
    "        \n",
    "        sqt_prev = np.array([0,0,0,0])\n",
    "        sqt2_prev = np.array([0,0,0,0])\n",
    "        \n",
    "        ##################################################################################################\n",
    "        # DESP\n",
    "        ##################################################################################################\n",
    "        \n",
    "        for rot in dataset[:-LAT_in_rows]:\n",
    "        #for rot in dataset[:10]:\n",
    "            \n",
    "            \n",
    "            #print(\"rot: \" + str(rot))\n",
    "            #print(\"-Ticke----------\")\n",
    "\n",
    "            f = alpha * t / (1 - alpha)\n",
    "            \n",
    "\n",
    "            sqt_w = (alpha * rot[0]) + ((f - alpha) * sqt_prev[0])\n",
    "            sqt_x = (alpha * rot[1]) + ((f - alpha) * sqt_prev[1])\n",
    "            sqt_y = (alpha * rot[2]) + ((f - alpha) * sqt_prev[2])\n",
    "            sqt_z = (alpha * rot[3]) + ((f - alpha) * sqt_prev[3])\n",
    "\n",
    "            sqt2_w = (alpha * sqt_w) + ((f - alpha) * sqt2_prev[0])\n",
    "            sqt2_x = (alpha * sqt_x) + ((f - alpha) * sqt2_prev[1])\n",
    "            sqt2_y = (alpha * sqt_y) + ((f - alpha) * sqt2_prev[2])\n",
    "            sqt2_z = (alpha * sqt_z) + ((f - alpha) * sqt2_prev[3])\n",
    "\n",
    "            q_pred_w = (2 + f) * sqt_w - (1 + f) * sqt2_w;\n",
    "            q_pred_x = (2 + f) * sqt_x - (1 + f) * sqt2_x;\n",
    "            q_pred_y = (2 + f) * sqt_y - (1 + f) * sqt2_y;\n",
    "            q_pred_z = (2 + f) * sqt_z - (1 + f) * sqt2_z;\n",
    "            \n",
    "            #Quaternion_result_norm = np.linalg.norm(np.array([q_pred_w, q_pred_x, q_pred_y, q_pred_z]))\n",
    "            #Quaternion_result = np.array([q_pred_w, q_pred_x, q_pred_y, q_pred_z])/Quaternion_result_norm\n",
    "            \n",
    "            q_res_unit = Quaternion([q_pred_w, q_pred_x, q_pred_y, q_pred_z]).unit\n",
    "            q_res_unit = np.array([q_res_unit[0],q_res_unit[1],q_res_unit[2],q_res_unit[3]])\n",
    "            \n",
    "            #print(q_res_unit)\n",
    "            \n",
    "            sqt_prev = Quaternion([sqt_w,sqt_x,sqt_y,sqt_z]).unit\n",
    "            sqt_prev = np.array([sqt_prev[0],sqt_prev[1],sqt_prev[2],sqt_prev[3]])\n",
    "            #print(sqt_prev)            \n",
    "            \n",
    "            sqt2_prev_normal = np.array([sqt2_w,sqt2_x,sqt2_y,sqt2_z])\n",
    "            #print(\"normal: \" + str(sqt2_prev_normal))\n",
    "            sqt2_prev = Quaternion([sqt2_w,sqt2_x,sqt2_y,sqt2_z]).unit\n",
    "            #print(\"Quat: \" + str(sqt2_prev))\n",
    "            sqt2_prev = np.array([sqt2_prev[0],sqt2_prev[1],sqt2_prev[2],sqt2_prev[3]])\n",
    "            #print(\"After :\" + str(sqt2_prev))\n",
    "            #print(\"-----\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            #sqt_prev_norm = np.linalg.norm(np.array([sqt_w,sqt_x,sqt_y,sqt_z]))\n",
    "            #sqt_prev = np.array([sqt_w,sqt_x,sqt_y,sqt_z])/sqt_prev_norm\n",
    "            \n",
    "            #sqt2_prev_norm = np.linalg.norm(np.array([sqt2_w,sqt2_x,sqt2_y,sqt2_z]))\n",
    "            #sqt2_prev = np.array([sqt2_w,sqt2_x,sqt2_y,sqt2_z])/sqt2_prev_norm\n",
    "            \n",
    "            prediction_result.append(q_res_unit)\n",
    "        \n",
    "        ##################################################################################################\n",
    "        # Checking continiousity of predicted data\n",
    "        ##################################################################################################\n",
    "        \n",
    "        dataset_pred = np.array(prediction_result)\n",
    "        dataset_pred = np.array([Quaternion(q) for q in dataset_pred]) \n",
    "        dataset_true = dataset[LAT_in_rows:]\n",
    "        \n",
    "        \n",
    "        \n",
    "        def representation_1(q):\n",
    "            quaternion = []\n",
    "            quaternion.append([q[0],q[1],q[2],q[3]])\n",
    "            return np.array(quaternion).reshape(4,)\n",
    "    \n",
    "        def representation_2(q):\n",
    "            quaternion = []\n",
    "            quaternion.append([-q[0],-q[1],-q[2],-q[3]])\n",
    "            return np.array(quaternion).reshape(4,)\n",
    "\n",
    "        for q1,q2 in zip(dataset_pred[:-1],dataset_pred[1:]):\n",
    "            if Quaternion.distance(q1,q2) <= Quaternion.distance(q1,-q2):\n",
    "                state_changes.append(0)\n",
    "            else:\n",
    "                state_changes.append(1)\n",
    "\n",
    "        cum_sum = np.cumsum(np.array(state_changes))\n",
    "\n",
    "        for idx,state in enumerate(cum_sum):\n",
    "            if state%2 == 0:\n",
    "                continious_dataset.append(representation_1(dataset_pred[idx+1]))\n",
    "            else:\n",
    "                continious_dataset.append(representation_2(dataset_pred[idx+1]))\n",
    "\n",
    "        \n",
    "        #print(\"Bevor\")\n",
    "        #print(dataset_pred)\n",
    "        #print(\"Groundtruth\")\n",
    "        #print(dataset_true)\n",
    "        #print(\"after\")\n",
    "        #print(np.array(continious_dataset))\n",
    "        \n",
    "        \n",
    "        euc_dists, ang_dists, mae_ang, mae_euc, rmse_ang, rmse_euc = eval_quat(continious_dataset, dataset_true[:-1])\n",
    "        \n",
    "        \n",
    "        # Create dataframe for prediction & gt per timestamp and concate results \n",
    "        df_preds_rot = pd.DataFrame(np.row_stack(continious_dataset), columns= cfg['quat_coords_pred'])\n",
    "        df_true_rot = pd.DataFrame(np.row_stack(dataset_true[:-1]), columns= cfg['quat_coords_true'])\n",
    "        df_rot_result = pd.concat([df_preds_rot, df_true_rot], axis=1)\n",
    "        df_rot_result.to_csv(os.path.join(Path_results_dataset01_DESP_quat_model_id + \"/Traces\", basename + '_result_quat_DESP.csv'), index=False)\n",
    "        print(\"Single Predictions are saved\")\n",
    "        \n",
    "        print('Number of dists: ' + str(euc_dists.shape[0]))\n",
    "        print('MAE_euc position is : ' + str(mae_euc))\n",
    "        print('RMSE_euc rotation is : ' + str(rmse_euc))\n",
    "        \n",
    "         ############ Save metrices\n",
    "        result_one_experiment = list([[mae_ang,mae_euc,rmse_ang,rmse_euc]])\n",
    "        df_results = pd.DataFrame(result_one_experiment, columns=['mae_ang','mae_euc','rmse_ang','rmse_euc'])\n",
    "        df_results.to_csv(os.path.join(Path_results_dataset01_DESP_quat_model_id + \"/Evaluation\", basename + '_quat_evaluation.csv'), index=False)\n",
    "\n",
    "        ############ Save angular distances\n",
    "        dist_one_experiment = list([[ang_dists,euc_dists]])\n",
    "        dists_one_experiment = pd.DataFrame(dist_one_experiment, columns=['ang_dists','euc_dists'])\n",
    "        dists_one_experiment.to_csv(os.path.join(Path_results_dataset01_DESP_quat_model_id + \"/Evaluation\", basename + '_quat_dists.csv'), index=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"----\")\n",
    "        print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-466-f448a2bfa24b>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-466-f448a2bfa24b>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    unit = Quaternion(0.048 +0.015i -0.999j -0.013k).unit\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])\n",
    "\n",
    "Quaternion_result_norm = np.linalg.norm(np.array([0.02956371 , 0.00830975 , 0.996813   , 0.07362611]))\n",
    "Quaternion_result_norm2 = np.linalg.norm([0.02956371 , 0.00830975 , 0.996813   , 0.07362611])\n",
    "\n",
    "Quaternion_result = np.array([q_pred_w, q_pred_x, q_pred_y, q_pred_z])/Quaternion_result_norm\n",
    "Quaternion_result2 = np.array([q_pred_w, q_pred_x, q_pred_y, q_pred_z])/Quaternion_result_norm\n",
    "\n",
    "print(Quaternion_result)\n",
    "print(Quaternion_result2)\n",
    "\n",
    "unit = Quaternion().unit\n",
    "print(unit)\n",
    "\n",
    "arr = np.array([unit[0],unit[1],unit[2],unit[3]])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        dataset_pred = np.array([Quaternion(q) for q in dataset_pred]) \n",
    "        dataset_true = np.array([Quaternion(q) for q in dataset_true])\n",
    "        \n",
    "        \n",
    "        \n",
    "        def representation_1(q):\n",
    "            quaternion = []\n",
    "            quaternion.append([q[0],q[1],q[2],q[3]])\n",
    "            return np.array(quaternion).reshape(4,)\n",
    "\n",
    "        def representation_2(q):\n",
    "            quaternion = []\n",
    "            quaternion.append([-q[0],-q[1],-q[2],-q[3]])\n",
    "            return np.array(quaternion).reshape(4,)\n",
    "        \n",
    "        \n",
    "        continious_dataset_pred = []\n",
    "        state_changes = []\n",
    "        \n",
    "        for yhat,ytrue in zip(dataset_pred,dataset_true):\n",
    "            \n",
    "            print(\"q1 = \" + str( Quaternion.distance(yhat,ytrue)))\n",
    "            print(\"q2 = \" + str( Quaternion.distance(-yhat,ytrue)))\n",
    "            \n",
    "            if Quaternion.distance(yhat,ytrue) <= Quaternion.distance(-yhat,ytrue):\n",
    "                state_changes.append(0)\n",
    "            else:\n",
    "                state_changes.append(1)\n",
    "\n",
    "        cum_sum = np.cumsum(np.array(state_changes))\n",
    "        print(cum_sum)\n",
    "\n",
    "        for idx,state in enumerate(cum_sum):\n",
    "\n",
    "            if state%2 == 0:\n",
    "                continious_dataset_pred.append(representation_1(dataset_pred[idx]))\n",
    "            else:\n",
    "                continious_dataset_pred.append(representation_2(dataset_pred[idx]))\n",
    "        \n",
    "        continious_dataset_pred = np.array(continious_dataset_pred)\n",
    "        print(continious_dataset_pred)\n",
    "        dataset_true = dataset[LAT_in_rows:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quat = np.array([Quaternion(q) for q in dataset]) \n",
    "continious_dataset = []\n",
    "state_changes = []\n",
    "dist = []\n",
    "\n",
    "def representation_1(q):\n",
    "    quaternion = []\n",
    "    quaternion.append([q[0],q[1],q[2],q[3]])\n",
    "    return np.array(quaternion).reshape(4,)\n",
    "    \n",
    "def representation_2(q):\n",
    "    quaternion = []\n",
    "    quaternion.append([-q[0],-q[1],-q[2],-q[3]])\n",
    "    return np.array(quaternion).reshape(4,)\n",
    "\n",
    "for yhat,ytrue in zip(dataset_pred,dataset_true):\n",
    "    if Quaternion.distance(yhat,ytrue) <= Quaternion.distance(yhat,ytrue):\n",
    "        state_changes.append(0)\n",
    "        dist.append(Quaternion.distance(q1,q2))\n",
    "    else:\n",
    "        state_changes.append(1)\n",
    "        dist.append(Quaternion.distance(q1,-q2))\n",
    "\n",
    "cum_sum = np.cumsum(np.array(state_changes))\n",
    "\n",
    "    \n",
    "for idx,state in enumerate(cum_sum):\n",
    "    \n",
    "    if state%2 == 0:\n",
    "        continious_dataset.append(representation_1(quat[idx+1]))\n",
    "    else:\n",
    "        continious_dataset.append(representation_2(quat[idx+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.45\n",
    "\n",
    "for pos in dataset:\n",
    "    pos_sqt_prev = pos\n",
    "    pos_sqt2_prev = pos\n",
    "    \n",
    "    result = PredictRotation()\n",
    "    #rot_sqt_prev \n",
    "    #rot_sqt2_prev  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public Vector3 PredictPosition(Vector3 pos, int t)\n",
    "{\n",
    "    float f = alpha * t / (1f - alpha);\n",
    "\n",
    "    Vector3 sqt = Vector3.zero;\n",
    "    sqt.x = (alpha * pos.x) + ((1f - alpha) * vec3_sqt_prev.x);\n",
    "    sqt.y = (alpha * pos.y) + ((1f - alpha) * vec3_sqt_prev.y);\n",
    "    sqt.z = (alpha * pos.z) + ((1f - alpha) * vec3_sqt_prev.z);\n",
    "\n",
    "    Vector3 sqt2 = Vector3.zero;\n",
    "    sqt2.x = (alpha * sqt.x) + ((1f - alpha) * vec3_sqt2_prev.x);\n",
    "    sqt2.y = (alpha * sqt.y) + ((1f - alpha) * vec3_sqt2_prev.y);\n",
    "    sqt2.z = (alpha * sqt.z) + ((1f - alpha) * vec3_sqt2_prev.z);\n",
    "\n",
    "    Vector3 vec3_pred = Vector3.zero;\n",
    "    vec3_pred.x = (2f + f) * sqt.x - (1f + f) * sqt2.x;\n",
    "    vec3_pred.y = (2f + f) * sqt.y - (1f + f) * sqt2.y;\n",
    "    vec3_pred.z = (2f + f) * sqt.z - (1f + f) * sqt2.z;\n",
    "    Vector3 result = new Vector3(vec3_pred.x, vec3_pred.y, vec3_pred.z);\n",
    "\n",
    "    vec3_sqt_prev = sqt;\n",
    "    vec3_sqt2_prev = sqt2;\n",
    "    return result;\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
